{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import PIL.Image as pil\n",
    "import numpy as np\n",
    "from numpy.matlib import repmat\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from skimage import io\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import glob\n",
    "import cv2\n",
    "from numpy.matlib import repmat\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: {}\".format(device))\n",
    "import math\n",
    "import os\n",
    "os.chdir('../..')\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Pointclouds\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    OpenGLOrthographicCameras, \n",
    "    PointsRasterizationSettings,\n",
    "    OpenGLPerspectiveCameras,\n",
    "    SfMPerspectiveCameras,\n",
    "    PointsRenderer,\n",
    "    PointsRasterizer,\n",
    "    AlphaCompositor,\n",
    "    NormWeightedCompositor\n",
    ")\n",
    "\n",
    "FOLDER_mpc_rgb = \"./synthesis_rgb\"\n",
    "FOLDER_mpc_disp = \"./synthesis_disp\"\n",
    "FOLDER_out = \"./synthesis_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_to_depth(disp, min_depth, max_depth):\n",
    "    \"\"\"Convert network's sigmoid output into depth prediction\n",
    "    The formula for this conversion is given in the 'additional considerations'\n",
    "    section of the paper.\n",
    "    \"\"\"\n",
    "    min_disp = 1 / max_depth\n",
    "    max_disp = 1 / min_depth\n",
    "    scaled_disp = min_disp + (max_disp - min_disp) * disp\n",
    "    depth = 1 / scaled_disp\n",
    "    return scaled_disp, depth\n",
    "\n",
    "def read_rgb(rgb_file):\n",
    "    \n",
    "    #rgb = io.imread(rgb_file)[:,:,:3]\n",
    "    im = Image.open(rgb_file)\n",
    "    \n",
    "    # Resize for mpc\n",
    "    width, height = im.size  \n",
    "    new_width = 600\n",
    "    new_height = 600\n",
    "    \n",
    "    im = im.resize((new_width, new_height))\n",
    "    rgb = np.array(im)[:,:,:3]\n",
    "    \n",
    "    return rgb\n",
    "\n",
    "def read_depth(depth_file):\n",
    "    \n",
    "    '''depth = io.imread(depth_file)\n",
    "    # Reference: https://carla.readthedocs.io/en/stable/cameras_and_sensors/#camera-depth-map\n",
    "    depth = depth[:, :, 0] * 1.0 + depth[:, :, 1] * 256.0 + depth[:, :, 2] * (256.0 * 256)\n",
    "    depth = depth * (1/ (256 * 256 * 256 - 1))'''\n",
    "    \n",
    "    disp = np.load(depth_file)\n",
    "    disp = torch.from_numpy(disp)\n",
    "    disp = torch.nn.functional.interpolate(disp, (600,600),mode=\"nearest\")\n",
    "    disp = disp.reshape((disp.shape[2],disp.shape[3]))\n",
    "    \n",
    "    _, depth = disp_to_depth(disp, 0.1, 100)\n",
    "    sc = 3.6\n",
    "    #sc = 1.45\n",
    "    depth = depth * sc\n",
    "    depth = depth.cpu().detach().numpy()\n",
    "    \n",
    "    return depth\n",
    "\n",
    "def get_rendered_image(depth, img, rel_pose12, K):\n",
    "    \n",
    "    rel_pose12 = rel_pose12.copy()\n",
    "    rel_pose12[0:2,3] *= -1\n",
    "    angles = rotationMatrixToEulerAngles(rel_pose12[:3,:3])\n",
    "    rel_pose12[:3,:3] = eulerAnglesToRotationMatrix(angles * np.array([1.0,1.0, -1.0]))\n",
    "\n",
    "    verts, color = depth_to_local_point_cloud(depth, color=img,k = K)\n",
    "    \n",
    "    # See also: \n",
    "    # https://github.com/facebookresearch/pytorch3d/blob/stable/docs/tutorials/render_colored_points.ipynb\n",
    "    \n",
    "    verts = torch.Tensor(verts).to(device)\n",
    "    rgb = torch.Tensor(color).to(device)\n",
    "    point_cloud = Pointclouds(points=[verts], features=[rgb])\n",
    "    \n",
    "    R = torch.from_numpy(rel_pose12[:3,:3].astype(np.float32)).unsqueeze(0)\n",
    "    T = torch.FloatTensor(1*rel_pose12[:3,3].astype(np.float32)).unsqueeze(0)\n",
    "    cameras = SfMPerspectiveCameras(device=device, R=R, T=T,\n",
    "                                        focal_length = torch.FloatTensor([[1,1]]),\n",
    "                                       principal_point = torch.FloatTensor([[0,0]]))\n",
    "\n",
    "    raster_settings = PointsRasterizationSettings(\n",
    "            image_size=img.shape[1] ,\n",
    "            radius = 0.01,\n",
    "            points_per_pixel = 100\n",
    "        )\n",
    "    \n",
    "    renderer = PointsRenderer(\n",
    "            rasterizer=PointsRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
    "            compositor=AlphaCompositor()\n",
    "        )\n",
    "\n",
    "    images = renderer(point_cloud)\n",
    "    return images[0, ..., :3].cpu().numpy()\n",
    "\n",
    "def depth_to_local_point_cloud(image, color=None, k = np.eye(3),max_depth=1.1):\n",
    "    \"\"\"\n",
    "    Convert an image containing CARLA encoded depth-map to a 2D array containing\n",
    "    the 3D position (relative to the camera) of each pixel and its corresponding\n",
    "    RGB color of an array.\n",
    "    \"max_depth\" is used to omit the p+oints that are far enough.\n",
    "    Reference: \n",
    "    https://github.com/carla-simulator/driving-benchmarks/blob/master/version084/carla/image_converter.py\n",
    "    \"\"\"\n",
    "    far = 1000.0  # max depth in meters.\n",
    "    normalized_depth = image# depth_to_array(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    # 2d pixel coordinates\n",
    "    pixel_length = width * height\n",
    "    u_coord = repmat(np.r_[width-1:-1:-1],\n",
    "                     height, 1).reshape(pixel_length)\n",
    "    v_coord = repmat(np.c_[height-1:-1:-1],\n",
    "                     1, width).reshape(pixel_length)\n",
    "\n",
    "    if color is not None:\n",
    "        color = color.reshape(pixel_length, 3)\n",
    "    normalized_depth = np.reshape(normalized_depth, pixel_length)\n",
    "\n",
    "    # Search for pixels where the depth is greater than max_depth to\n",
    "    # delete them\n",
    "\n",
    "    # pd2 = [u,v,1]\n",
    "    p2d = np.array([u_coord, v_coord, np.ones_like(u_coord)])\n",
    "\n",
    "    # P = [X,Y,Z]\n",
    "    p3d = np.dot(np.linalg.inv(k), p2d)\n",
    "    p3d *= normalized_depth \n",
    "    p3d = np.transpose(p3d, (1,0))\n",
    "    return p3d, color / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://learnopencv.com/rotation-matrix-to-euler-angles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRotationMatrix(R) :\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def rotationMatrixToEulerAngles(R) :\n",
    "\n",
    "    assert(isRotationMatrix(R))\n",
    "    \n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    \n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])*180/np.pi\n",
    "\n",
    "# Calculates Rotation Matrix given euler angles.\n",
    "def eulerAnglesToRotationMatrix(theta) :\n",
    "    \n",
    "    theta *= np.pi / 180\n",
    "    \n",
    "    R_x = np.array([[1,         0,                  0                   ],\n",
    "                    [0,         math.cos(theta[0]), -math.sin(theta[0]) ],\n",
    "                    [0,         math.sin(theta[0]), math.cos(theta[0])  ]\n",
    "                    ])\n",
    "        \n",
    "        \n",
    "                    \n",
    "    R_y = np.array([[math.cos(theta[1]),    0,      math.sin(theta[1])  ],\n",
    "                    [0,                     1,      0                   ],\n",
    "                    [-math.sin(theta[1]),   0,      math.cos(theta[1])  ]\n",
    "                    ])\n",
    "                \n",
    "    R_z = np.array([[math.cos(theta[2]),    -math.sin(theta[2]),    0],\n",
    "                    [math.sin(theta[2]),    math.cos(theta[2]),     0],\n",
    "                    [0,                     0,                      1]\n",
    "                    ])\n",
    "                    \n",
    "                    \n",
    "    R = np.dot(R_x, np.dot( R_y, R_z ))\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example showing how image rendering works (shifting the camera's position horizontally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list_pos = os.listdir(FOLDER_mpc_rgb)\n",
    "id_list_pos.sort()\n",
    "# Add folders to be synthesized to the list \n",
    "id_list_pos = [\"pos178\"]                      \n",
    "cam_rgb = \"center\"\n",
    "cam_disp = \"disp_center\"\n",
    "translation_arr = [-0.25, 0.25, -0.50, 0.50, -0.75, 0.75, -1.0, 1.0, -1.25, 1.25, -1.50, 1.50]\n",
    "for x in range(0, len(translation_arr)):\n",
    "    for pos in range(0, len(id_list_pos)):\n",
    "        position = id_list_pos[pos]\n",
    "        print(\"Translation is: {}\".format(translation_arr[x]))\n",
    "        id_list_frames = os.listdir(os.path.join(FOLDER_mpc_rgb, position, \"gt\", cam_rgb))\n",
    "        id_list_frames.sort()\n",
    "        for fr in range(0, len(id_list_frames)):\n",
    "            frame_no = id_list_frames[fr]\n",
    "            rgb_file1_mpc   = os.path.join(FOLDER_mpc_rgb, position, \"gt\", cam_rgb, frame_no)\n",
    "            depth_file1_mpc = os.path.join(FOLDER_mpc_disp, position, cam_disp, frame_no[:-4] + \".npy\")\n",
    "            \n",
    "            K = np.array([[300, 0.0, 300.0],\n",
    "                         [0.0, 300, 300],\n",
    "                         [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "            rgb1 = read_rgb(rgb_file1_mpc)\n",
    "            # Note that the depth values below are normalized to between 0 and 1. \n",
    "            depth1 = read_depth(depth_file1_mpc)\n",
    "            transformation = np.eye(4)\n",
    "            transformation[0,3] = translation_arr[x]\n",
    "            rendered_image = get_rendered_image(depth1, rgb1, transformation, K)\n",
    "            rendered_image = (rendered_image *255).astype(np.uint8)        \n",
    "            im = pil.fromarray(rendered_image)\n",
    "            if x % 2 == 0:\n",
    "                save_folder = \"right\"\n",
    "                if x != 0:\n",
    "                    save_folder = \"right{}\".format(int(x/2)+1)\n",
    "            elif x % 2 != 0:\n",
    "                save_folder = \"left\"\n",
    "                if x != 1:\n",
    "                    save_folder = \"left{}\".format(int(int(x-1)/2)+1)\n",
    "\n",
    "            save_path = os.path.join(FOLDER_out, position, save_folder, id_list_frames[fr][:-4] + \".png\".format(x))\n",
    "            if not os.path.exists(os.path.join(FOLDER_out, position)):\n",
    "                os.mkdir(os.path.join(FOLDER_out, position))\n",
    "            if not os.path.exists(os.path.join(FOLDER_out, position, save_folder)):\n",
    "                os.mkdir(os.path.join(FOLDER_out, position, save_folder))\n",
    "\n",
    "            #Resize to original size                              \n",
    "            im = im.resize((1200,600))\n",
    "                              \n",
    "            #Center crop\n",
    "            width, height = im.size   # Get dimensions\n",
    "            new_width = 1000\n",
    "            new_height = 600\n",
    "\n",
    "            rgb = np.array(im)[:,:,:3]\n",
    "            left = (width - new_width)/2\n",
    "            top = (height - new_height)/2\n",
    "            right = (width + new_width)/2\n",
    "            bottom = (height + new_height)/2\n",
    "            im = im.crop((left, top, right, bottom))\n",
    "            im = im.resize((128, 128))\n",
    "            rgb = np.array(im)[:,:,:3]\n",
    "            \n",
    "            im = pil.fromarray(rgb)\n",
    "            im.save(save_path)\n",
    "            print(save_path)\n",
    " \n",
    "         \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
